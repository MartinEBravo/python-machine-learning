{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text from a Book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1143k  100 1143k    0     0   829k      0  0:00:03  0:00:01  0:00:02  367k    0  0:00:01  0:00:01 --:--:--  828k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://www.gutenberg.org/files/1268/1268-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS ISLAND ***\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THE MYSTERIOUS ISLAND\n",
      "\n",
      "by Jules Verne\n",
      "\n",
      "1874\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "PART 1--DROPPED FROM T == Encoding ==> [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1 37 47 40 29 42 32  1 10 10\n",
      " 10  0  0  0  0  0 48 36 33  1 41 53 47 48 33 46 37 43 49 47  1 37 47 40\n",
      " 29 42 32  0  0 56 79  1 38 75 66 59 73  1 50 59 72 68 59  0  0 16 23 22\n",
      " 19  0  0  0  0  0 44 29 46 48  1 16 12 12 32 46 43 44 44 33 32  1 34 46\n",
      " 43 41  1 48]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('1268-0.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_indx:end_indx]\n",
    "chars_set = set(text)\n",
    "\n",
    "chars_sorted = sorted(chars_set)\n",
    "char2int = {ch: i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "\n",
    "print(text[:100], '== Encoding ==>', text_encoded[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded)-chunk_size+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/w5pp8km560dfjlrqkfg6yrg00000gn/T/ipykernel_11320/1527608599.py:12: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.text_chunks[idx][:-1].long(), self.text_chunks[idx][1:].long()\n",
    "    \n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "torch.manual_seed(42)\n",
    "seq_dataloader = DataLoader(seq_dataset, batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, # amount of characters\n",
    "            embed_dim # size of the embedding vector\n",
    "            )\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn = nn.LSTM(\n",
    "            embed_dim, # size of the input embedding vector\n",
    "            rnn_hidden_size, # size of the hidden state\n",
    "            batch_first=True\n",
    "            )\n",
    "        self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        out = self.embedding(x).unsqueeze(1)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = self.fc(out).reshape(out.size(0), -1)\n",
    "        return out, hidden, cell\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(85, 256)\n",
       "  (rnn): LSTM(256, 512, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=85, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(char_array)\n",
    "embed_dim = 256\n",
    "rnn_hidden_size = 512\n",
    "\n",
    "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 70.9976\n",
      "Epoch 200/1000, Loss: 61.7498\n",
      "Epoch 300/1000, Loss: 58.8974\n",
      "Epoch 400/1000, Loss: 61.2124\n",
      "Epoch 500/1000, Loss: 54.6316\n",
      "Epoch 600/1000, Loss: 55.2262\n",
      "Epoch 700/1000, Loss: 54.7025\n",
      "Epoch 800/1000, Loss: 55.0149\n",
      "Epoch 900/1000, Loss: 55.3729\n",
      "Epoch 1000/1000, Loss: 53.3664\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    hidden, cell = model.init_hidden(batch_size)\n",
    "    seq_batch, target_batch = next(iter(seq_dataloader))\n",
    "    optimizer.zero_grad()\n",
    "    loss = 0\n",
    "    for c in range(seq_length):\n",
    "        pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
    "        loss += loss_fn(pred, target_batch[:, c])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss += loss.item()/seq_length\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "def sample(model, starting_str, \n",
    "           len_generated_text=500, \n",
    "           scale_factor=1.0):\n",
    "\n",
    "    encoded_input = torch.tensor([char2int[s] for s in starting_str])\n",
    "    encoded_input = torch.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.eval()\n",
    "    hidden, cell = model.init_hidden(1)\n",
    "    hidden = hidden.to('cpu')\n",
    "    cell = cell.to('cpu')\n",
    "    for c in range(len(starting_str)-1):\n",
    "        _, hidden, cell = model(encoded_input[:, c].view(1), hidden, cell) \n",
    "    \n",
    "    last_char = encoded_input[:, -1]\n",
    "    for i in range(len_generated_text):\n",
    "        logits, hidden, cell = model(last_char.view(1), hidden, cell) \n",
    "        logits = torch.squeeze(logits, 0)\n",
    "        scaled_logits = logits * scale_factor\n",
    "        m = Categorical(logits=scaled_logits)\n",
    "        last_char = m.sample()\n",
    "        yield char_array[last_char]\n",
    "        sleep(0.05)\n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ad shumen soepus fire it actuded, my ffirm good aurmousd, was down, but helted prupercoad as\n",
      "fifteer is neim: direction of the mind\n",
      "from kind thovemenable artances, and agreets a goved in an’thets, then\n",
      "gentimes which imaen, Ayrton. “Deverew them kind, grautilieves with critef him! It was if they unfaund\n",
      "Brot’s chowVard. 3\n",
      "tide one’s\n",
      "o’cquarus.\n",
      "The trangars, if a horizon’, levelves qearcoll, and\n",
      "fallen articlevellow at\n",
      "that days in wild, but when it attempts eStrain\n",
      "swagers!\n",
      "\n",
      "It is\n",
      "Washed! Cyru"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "model.to('cpu')\n",
    "\n",
    "stream = sample(model, starting_str='The island was', len_generated_text=500, scale_factor=0.7)\n",
    "\n",
    "for c in stream:\n",
    "    print(c, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
